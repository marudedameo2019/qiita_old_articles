---
title: Windowsのmutexとeventの性能
tags: Windows C++ 同期処理
author: dameyodamedame
slide: false
---
# 序

私が書いた以下の記事のコメントで、Cランタイムでの同期機構の実装について指摘がありました。

https://qiita.com/dameyodamedame/items/ab39311ddc2ef06abfc8#comment-2fdc29723e050ec453a1

> Kernel ObjectのHANDLE Eventより、自プロセス限定の制約をつけて動くCONDITION_VARIABLEの方が速い

> std::mutexですが、これの(現時点での)VisualC++ Runtimeにおける実装はSRWLOCKで、Kernel ObjectのHANDLE MutexやCRITICAL_SECTION とも別物になります

ただ日本語での資料などもなく、英語の資料でも事実や検証結果ではなく、内部情報に基づく話なのか、情報が少なく、自分で検証ができなかったので、簡単に性能比較だけしておこうと記事を起こした次第です。

(追記)コメントで指摘されたのですが、UCRTのC++標準ライブラリ(msvcp*.dll)のソースコードは公開されているようです。正確にはこちらで確定できます。

# 性能比較

## lock編

> std::mutexですが、これの(現時点での)VisualC++ Runtimeにおける実装はSRWLOCKで、Kernel ObjectのHANDLE MutexやCRITICAL_SECTION とも別物になります

まずはこちらの調査からです。

### 調査用コード

```c++:some_lock.cpp
#include <iostream>
#include <atomic>
#include <mutex>
#include <vector>
#include <memory>
#include <Windows.h>

template<typename Out>
void print_env(Out& out) {

#define PRINT_MACRO(VAR) out << #VAR ": " << VAR << std::endl
    PRINT_MACRO(_MSC_FULL_VER);
    PRINT_MACRO(_MSVC_LANG);
    PRINT_MACRO(_WIN64);
    PRINT_MACRO(_MT);
#ifdef _DEBUG
    out << "with _DEBUG" << std::endl;
#else
    out << "without _DEBUG" << std::endl;
#endif
    PRINT_MACRO(_DLL);
#undef PRINT_MACRO
}

void exec_systeminfo() {
    system("systeminfo | findstr /r \"^OS.バ\"");
    system("systeminfo | findstr /r \"^システムの種類\"");
}

using namespace std;

template<typename T>
size_t lock_loop(atomic_bool& stop, T& lockable) {
    size_t count = 0;
    while (!stop) {
        lock_guard<T> l(lockable);
        if (++count == 0) throw runtime_error("count overflow");
    }
    return count;
}

struct my_critical_section {
    CRITICAL_SECTION cs;
    my_critical_section() {::InitializeCriticalSection(&cs);}
    ~my_critical_section() {::DeleteCriticalSection(&cs);}
    void lock() {::EnterCriticalSection(&cs);}
    void unlock() {::LeaveCriticalSection(&cs);}
};

struct my_mutex {
    HANDLE  handle;
    my_mutex(): handle(::CreateMutex(NULL, FALSE, NULL)){}
    ~my_mutex() {if (handle != NULL) ::CloseHandle(handle);}
    void lock() {::WaitForSingleObject(handle, INFINITE);}
    void unlock() {::ReleaseMutex(handle);}
};

struct my_srwlock {
    SRWLOCK srwlock;
    my_srwlock() {InitializeSRWLock(&srwlock);}
    ~my_srwlock() {}
    void lock() {::AcquireSRWLockExclusive(&srwlock);}
    void unlock() {::ReleaseSRWLockExclusive(&srwlock);}
};


template<typename T>
size_t lock_loop_mt(atomic_bool& stop, T& lockable, size_t C=1) {
    vector<unique_ptr<thread>> threads;
    vector<size_t> result(C);
    for (size_t i = 0; i < C; ++i) {
        threads.emplace_back(std::make_unique<thread>([&, i] {
            result[i] = lock_loop(stop, lockable);
        }));
    }
    for (auto& pt : threads) {
        pt->join();
    }
    size_t sum = 0;
    for (auto x : result) {
        size_t new_sum = sum + x;
        if (sum > new_sum) throw runtime_error("count overflow");
        sum = new_sum;
    }
    return sum;
}

template<typename T>
void test(const char* prefix) {
    SYSTEM_INFO info;
    ::GetSystemInfo(&info);
    for (int i = 1; i < static_cast<int>(info.dwNumberOfProcessors); ++i) {
        T m;
        atomic_bool stop = false;
        size_t result = 0;
        thread t([&] {
            result = lock_loop_mt<T>(stop, m, i + 1);
        });
        this_thread::sleep_for(3s);
        stop = true;
        t.join();
        cout << prefix << i + 1 << "," << result << endl;
    }
}

int main()
{
    print_env(std::cout);
    exec_systeminfo();
    cout << "method,threads,count" << endl;
    test<mutex>("std::mutex,");
    test<my_critical_section>("my_critical_section,");
    test<my_mutex>("my_mutex,");
    test<my_srwlock>("my_srwlock,");
    return 0;
}
```

### 計測内容

ロックを行う用の同期オブジェクトを3秒間複数スレッドからロック/アンロックを繰り返し、合計ロック/アンロック回数を計測する、というものです。3秒sleepして止めるロジックなので誤差はそれなりにあると思います。同期オブジェクトは以下の4つです。

|ラベル|クラス説明|
|:--|:--|
|std::mutex|std::mutex|
|my_critical_section|WIN32APIのCRITICAL_SECTIONを直に使ったクラス|
|my_mutex|WIN32APIのMutexを直に使ったクラス|
|my_srwlock|WIN32APIのSlim Read/Write Lockを直に使ったクラス|

### 実行結果

紹介された記事にはランタイムのバージョンごとに割と実装が変わるらしい記述もあったので、重い腰を上げてVS2022を入れてみました。なので、今までのVC++2019に加えてVC++2022の結果も貼ってあります。

#### VC++2019
```text:some_lock_2019.log
_MSC_FULL_VER: 192930154
_MSVC_LANG: 201402
_WIN64: 1
_MT: 1
without _DEBUG
_DLL: 1
OS バージョン:          10.0.19045 N/A ビルド 19045
システムの種類:         x64-based PC
method,threads,count
std::mutex,2,134885091
std::mutex,3,103973503
std::mutex,4,88573850
std::mutex,5,84930691
std::mutex,6,77355277
std::mutex,7,76379850
std::mutex,8,70513501
my_critical_section,2,112188534
my_critical_section,3,60967026
my_critical_section,4,44632726
my_critical_section,5,38284619
my_critical_section,6,34272880
my_critical_section,7,29147091
my_critical_section,8,26136282
my_mutex,2,927048
my_mutex,3,812630
my_mutex,4,850513
my_mutex,5,825345
my_mutex,6,858044
my_mutex,7,831086
my_mutex,8,854777
my_srwlock,2,154869370
my_srwlock,3,126412069
my_srwlock,4,110878114
my_srwlock,5,101760216
my_srwlock,6,93650614
my_srwlock,7,85924241
my_srwlock,8,86344388
```

#### VC++2022
```text:some_lock_2022.log
_MSC_FULL_VER: 194033813
_MSVC_LANG: 201402
_WIN64: 1
_MT: 1
without _DEBUG
_DLL: 1
OS バージョン:          10.0.19045 N/A ビルド 19045
システムの種類:         x64-based PC
method,threads,count
std::mutex,2,122088151
std::mutex,3,106855420
std::mutex,4,92216098
std::mutex,5,86139474
std::mutex,6,82722591
std::mutex,7,72405990
std::mutex,8,70830667
my_critical_section,2,77478429
my_critical_section,3,64922044
my_critical_section,4,46566493
my_critical_section,5,39094056
my_critical_section,6,34190706
my_critical_section,7,29833863
my_critical_section,8,26726330
my_mutex,2,1010521
my_mutex,3,836488
my_mutex,4,863373
my_mutex,5,832158
my_mutex,6,861514
my_mutex,7,838252
my_mutex,8,858856
my_srwlock,2,142227240
my_srwlock,3,123767663
my_srwlock,4,102759232
my_srwlock,5,100866750
my_srwlock,6,92794490
my_srwlock,7,85364953
my_srwlock,8,78265102
```

### グラフ

![some_lock.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/570812/fe3a5f53-48f1-a8d0-a23d-08f1778c7e94.png)

### 考察

異常系実装のないAPI直呼びsrwlockが多少速く、次いでstd::mutex、API直呼びCRITICAL_SECTIONの順で、API直呼びMutexは悲惨な結果になっていますね。プロセス考慮なだけでこれだけ遅くなるのでしょうか？

定性的な結果だけ見ると、std::mutexがsrwlockで実装されているという話は信憑性が高いように見えます。

あとなぜかスレッド数2のときは2019の方が速い傾向があるようです。スピン回数に違いがあるのかも知れません。

## event編

> Kernel ObjectのHANDLE Eventより、自プロセス限定の制約をつけて動くCONDITION_VARIABLEの方が速い

次はこれです。

### 調査用コード

```c++:some_event.cpp
#include <iostream>
#include <atomic>
#include <mutex>
#include <vector>
#include <memory>
#include <Windows.h>

template<typename Out>
void print_env(Out& out) {

#define PRINT_MACRO(VAR) out << #VAR ": " << VAR << std::endl
    PRINT_MACRO(_MSC_FULL_VER);
    PRINT_MACRO(_MSVC_LANG);
    PRINT_MACRO(_WIN64);
    PRINT_MACRO(_MT);
#ifdef _DEBUG
    out << "with _DEBUG" << std::endl;
#else
    out << "without _DEBUG" << std::endl;
#endif
    PRINT_MACRO(_DLL);
#undef PRINT_MACRO
}

void exec_systeminfo() {
    system("systeminfo | findstr /r \"^OS.バ\"");
    system("systeminfo | findstr /r \"^システムの種類\"");
}

using namespace std;

struct my_event_with_std {
    bool state;
    condition_variable cond;
    my_event_with_std() : state(false) {}
    my_event_with_std(const my_event_with_std&) = delete;
    my_event_with_std(my_event_with_std&&) = delete;
    my_event_with_std& operator=(const my_event_with_std&) = delete;
    my_event_with_std& operator=(my_event_with_std&&) = delete;
    template <typename T>
    void set(T& l) {
        this->cond.wait(l, [=] {return !this->state; });
        this->state = true;
        this->cond.notify_all();
    }
    template <typename T>
    void reset(T& l) {
        this->cond.wait(l, [=] {return this->state; });
        this->state = false;
        this->cond.notify_all();
    }
};

struct my_event_with_api {
    HANDLE handle;
    bool state;
    my_event_with_api(): handle(::CreateEvent(NULL, FALSE, FALSE, NULL)), state(false) {}
    ~my_event_with_api() {
        if (handle != NULL) ::CloseHandle(handle);
    }
    template<typename T>
    void set(T& l) {
        if (state) {
            while (state) {
                l.unlock();
                ::WaitForSingleObject(handle, INFINITE);
                l.lock();
            }
            state = true;
            ::ResetEvent(handle);
        }
        else {
            state = true;
            ::SetEvent(handle);
        }
    }
    template<typename T>
    void reset(T& l) {
        if (state) {
            state = false;
            ::SetEvent(handle);
        }
        else {
            while (state) {
                l.unlock();
                ::WaitForSingleObject(handle, INFINITE);
                l.lock();
            }
            state = false;
            ::ResetEvent(handle);
        }
    }
};

#include <queue>
#include <chrono>
using namespace std::chrono;
template<typename T>
size_t event_link_loop_mt(atomic_bool& stop, size_t C = 2) {
    vector<unique_ptr<thread>> threads;
    vector<unique_ptr<T>> events;
    struct log_data {
        high_resolution_clock::time_point tp;
        thread::id tid;
        size_t event_idx;
        bool is_set;
    };
    queue<log_data> event_log;
    auto log = [&](size_t event_idx, bool is_set) {
        //event_log.emplace(log_data{high_resolution_clock::now(), this_thread::get_id(), event_idx, is_set});
    };
    auto start = high_resolution_clock::now();
    for (size_t i = 0; i < C; ++i) {
        events.emplace_back(make_unique<T>());
    }
    mutex m;
    unique_lock<mutex> l(m);
    for (size_t i = 0; i < C; ++i) {
        events[i]->set(l);
        log(i, true);
    }
    for (size_t i = 0; i < C - 1; ++i) {
        threads.emplace_back(std::make_unique<thread>([&, i] {
            while (! stop) {
                unique_lock<mutex> l(m);
                events[i]->set(l);
                log(i, true);
                events[i+1]->reset(l);
                log(i+1, false);
            }
        }));
    }
    size_t count = 0;
    while (! stop) {
        events[0]->reset(l);
        log(0, false);
        events[C - 1]->set(l);
        log(C - 1, true);
        if (count + 1 == 0) throw runtime_error("count overflow");
        ++count;
    }
    events[0]->reset(l);
    log(0, false);
    l.unlock();
    for (auto& pt : threads) {
        pt->join();
    }
    while (!event_log.empty()) {
        const auto& line = event_log.front();
        cerr << "[" << duration_cast<nanoseconds>(line.tp - start).count() / 1000000000. << "]: " << "tid =" << line.tid << " event_idx=" << line.event_idx << " is_set=" << line.is_set << "\n";
        event_log.pop();
    }
    cerr.flush();
    return count;
}

template<typename T>
void test(const char* prefix) {
    SYSTEM_INFO info;
    ::GetSystemInfo(&info);
    for (int i = 1; i < static_cast<int>(info.dwNumberOfProcessors); ++i) {
        T m;
        atomic_bool stop = false;
        size_t result = 0;
        thread t([&] {
            result = event_link_loop_mt<T>(stop, i + 1);
        });
        this_thread::sleep_for(3s);
        stop = true;
        t.join();
        cout << prefix << i + 1 << "," << result << endl;
    }
}

int main()
{
    print_env(std::cout);
    exec_systeminfo();
    cout << "method,threads,count" << endl;
    test<my_event_with_std>("my_event_with_std,");
    test<my_event_with_api>("my_event_with_api,");
    return 0;
}
```

### 計測内容

複数スレッドを使い、数珠繋ぎにしたEventで待機からシグナルを3秒間繰り返し、合計シグナル回数(最初の発信のみカウント)を計測する、というものです。3秒sleepして止めるロジックなので誤差はそれなりにあると思います。同期オブジェクトは以下の2つです。

|ラベル|クラス説明|
|:--|:--|
|my_event_with_std|std::condition_variableを使ったクラス|
|my_event_with_api|WIN32APIのEventオブジェクトを直に使ったクラス|

### 実行結果

ロック編と同様の形式です。

#### VC++2019
```text:some_event_2019.log
_MSC_FULL_VER: 192930154
_MSVC_LANG: 201402
_WIN64: 1
_MT: 1
without _DEBUG
_DLL: 1
OS バージョン:          10.0.19045 N/A ビルド 19045
システムの種類:         x64-based PC
method,threads,count
my_event_with_std,2,3121516
my_event_with_std,3,273156
my_event_with_std,4,180888
my_event_with_std,5,131757
my_event_with_std,6,119261
my_event_with_std,7,103954
my_event_with_std,8,83010
my_event_with_api,2,427247
my_event_with_api,3,252875
my_event_with_api,4,195084
my_event_with_api,5,152479
my_event_with_api,6,131350
my_event_with_api,7,109653
my_event_with_api,8,97111
```

#### VC++2022
```text:some_event_2022.log
_MSC_FULL_VER: 194033813
_MSVC_LANG: 201402
_WIN64: 1
_MT: 1
without _DEBUG
_DLL: 1
OS バージョン:          10.0.19045 N/A ビルド 19045
システムの種類:         x64-based PC
method,threads,count
my_event_with_std,2,3184393
my_event_with_std,3,279608
my_event_with_std,4,181913
my_event_with_std,5,134356
my_event_with_std,6,118288
my_event_with_std,7,103299
my_event_with_std,8,83194
my_event_with_api,2,428328
my_event_with_api,3,245006
my_event_with_api,4,195109
my_event_with_api,5,147336
my_event_with_api,6,132353
my_event_with_api,7,106558
my_event_with_api,8,97926
```

### グラフ

![some_event.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/570812/d2c2d12e-84cb-41b0-b3ab-c79c4ff7f089.png)

### 考察

こちらは不思議な結果になり、スレッド数2まではstd::condition_variableが速いのですが、3以降はEventオブジェクトとほぼ変わらない結果になりました。スレッド数2ということは待機が1ということですが、それの処理が速いことは有利であることは間違いないのですが、その気になればプロセスをまたぐことが出来るEventオブジェクトと3以降変わらないのがWindowsの底力なのかもしれません。待機が複数になるとスレッドの起きる順番が影響するので、外れてしまったときの時間が足を引っ張る形なのかと妄想しています(スピンで待てるとか待てないとか)。

## プロット用コード(保管用)

```console
(env)C:\>pip install pandas matplotlib
```

```python:plot.py
import sys
import pandas as pd
import matplotlib.pyplot as plt
from io import StringIO

def read_log(fname):
    with open(fname, 'r') as f, StringIO(''.join(filter(lambda x: ': ' not in x and not x.startswith('with'), f))) as s:
        return pd.read_csv(s)

def get_df(fname_prefix, version):
    df = read_log(fname_prefix + f'_{version}.log')
    df.insert(0, 'compiler', f'vs{version}')
    return df

def plot(df, target, target_fname):
    df = df.set_index(['threads', 'compiler', 'method'])
    df = df.unstack(['compiler', 'method'])
    df = df.stack(level=0)
    df = df.reset_index(level=1, drop=True)
    print(df)
    plt.figure()
    ax = df.plot()
    ax.set_title(target)
    ax.set_xlabel('number of threads')
    ax.set_ylabel('count(performance)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)
    plt.savefig(f'{target_fname}.svg'.replace(' ','_'), bbox_inches='tight')
    plt.savefig(f'{target_fname}.png'.replace(' ','_'), bbox_inches='tight')

versions = ['2019', '2022']
for target in ['some lock', 'some_event']:
    target_fname = target.replace(' ','_')
    df = pd.concat([get_df(target_fname, vers) for vers in versions])
    plot(df, target, target_fname)
```

# まとめ

- std::mutexはsrwlockで実装されてるような定性的結果が得られた
- std::condition_variableとeventはスレッド数3以降有意な差がないように見える

