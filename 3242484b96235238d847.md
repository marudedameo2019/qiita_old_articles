---
title: スレッドを使ってみる
tags: C++ マルチスレッド
author: dameyodamedame
slide: false
---
# 序

前回はepollを使ってシングルスレッドな非同期な処理(といってもpromiseでもawaitでもない昔ながらのコールバックモデル)で、並行処理を書いてみました。

今回はstd::threadを使ったマルチスレッドを少し齧ってみます。マルチスレッドではイベントループなどと違い、各スレッドが同時に動作します(イベントループではコールバックされるだけで同時に実行される処理は常に1つでした)。同時に動作する処理が同じメモリを通信などをすることなく簡単に参照出来るので、とても記述が楽なのですが、スレッド間で同じ変数を読み書きすると、いわゆる**競合**というやつが発生し、不思議な現象が起きます。

# マルチスレッドで競合

```c++
#include <iostream>
#include <thread>
#include <vector>

class hoge {
    int value;
    std::vector<std::thread> threads;
public:
    hoge(): value(0), threads(0) {}
    void start() {threads.emplace_back(std::thread(func, this));}
    static void func(hoge* instance) {
        for(int i = 0; i < 10000; ++i) instance->value++;
    }
    int join() {
        for (auto& t: threads) t.join();
        return value;
    }
};

int main() {
    hoge o;
    for (int i = 0; i < 100; ++i) o.start();
    std::cout << o.join() << std::endl;
    return 0;
}
```
100個のスレッドを使って、共有しているカウンタをそれぞれ10000回インクリメントするプログラムです。最後に表示される数字が全スレッド終了時のカウンタの値になります。
早速実行してみると…
```console
$ g++ --version
g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Copyright (C) 2021 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

$ g++ -g hoge.cpp -o hoge
$ ./hoge
604448
$
```
あれ？100 * 10000 = 1000000のはずなのに随分少なくなっています。

これは**競合**(正確にはデータ競合)が発生しているためで、複数のスレッドが同時にインクリメントすることにより、**同じ値をインクリメントして同じ値を書き込んだ複数のスレッドがあった**ということになります。実際にディスアセンブルしてみると(amd64)…

```console
$ objdump -S hoge | less
...
    static void func(hoge* instance) {
    16a6:       f3 0f 1e fa             endbr64 
    16aa:       55                      push   %rbp
    16ab:       48 89 e5                mov    %rsp,%rbp
    16ae:       48 89 7d e8             mov    %rdi,-0x18(%rbp)
        for(int i = 0; i < 10000; ++i) instance->value++;
    16b2:       c7 45 fc 00 00 00 00    movl   $0x0,-0x4(%rbp)
    16b9:       eb 13                   jmp    16ce <_ZN4hoge4funcEPS_+0x28>
    16bb:       48 8b 45 e8             mov    -0x18(%rbp),%rax
    16bf:       8b 00                   mov    (%rax),%eax
    16c1:       8d 50 01                lea    0x1(%rax),%edx
    16c4:       48 8b 45 e8             mov    -0x18(%rbp),%rax
    16c8:       89 10                   mov    %edx,(%rax)
    16ca:       83 45 fc 01             addl   $0x1,-0x4(%rbp)
    16ce:       81 7d fc 0f 27 00 00    cmpl   $0x270f,-0x4(%rbp)
    16d5:       7e e4                   jle    16bb <_ZN4hoge4funcEPS_+0x15>
    }
    16d7:       90                      nop
    16d8:       90                      nop
    16d9:       5d                      pop    %rbp
    16da:       c3                      ret    
    16db:       90                      nop
...
```
実際にインクリメントしている部分は
```console
    16bb:       48 8b 45 e8             mov    -0x18(%rbp),%rax
    16bf:       8b 00                   mov    (%rax),%eax
    16c1:       8d 50 01                lea    0x1(%rax),%edx
    16c4:       48 8b 45 e8             mov    -0x18(%rbp),%rax
    16c8:       89 10                   mov    %edx,(%rax)
```
になります。

あるスレッドが16c1を実行しようとしてるときに別スレッドが16bfを実行してたら同じ値を読んでしまい、結果同じ値を書き込んでしまいますよね。すると数が合わない現象も容易に想像が出来ます。

# 最適化してみる

インクリメントが5命令にもなっていたために、読み込みと書き込みが分かれて、同じ値のインクリメントが同時に起きたのなら、最適化をして読み込みと書き込みが一緒になれば改善するかもしれません。早速やってみると…

```console
$ g++ -g -O3 hoge.cpp -o hoge
$ ./hoge
1000000
$
```

おおお！結果は正しそうです。でもちょっと待ってください。ディスアセンブル結果も意図通りとは限りません。

```console
$ objdump -S hoge | less
...
    static void func(hoge* instance) {
    1590:       f3 0f 1e fa             endbr64 
        for(int i = 0; i < 10000; ++i) instance->value++;
    1594:       81 07 10 27 00 00       addl   $0x2710,(%rdi)
    }
    159a:       c3                      ret    
    159b:       0f 1f 44 00 00          nopl   0x0(%rax,%rax,1)
...
```

10000足しとる！違うそうじゃない…
1ずつ足して欲しいのです…

結果の数字こそ正しくなりましたが、そもそも起動後1回だけ足し算するだけだと同時実行が起きない可能性が高く、やりたいことは全然出来ていません。最適化が効きすぎているようです。

# volatileを使う

そこで最適化を抑制してくれる[volatile](https://ja.cppreference.com/w/cpp/language/cv)を変数に指定してみます。
```c++
    volatile int value;
```
メンバ変数をこう書き換えるだけです。実行してみると…
```console
$ g++ -g -O3 hoge.cpp -o hoge
$ ./hoge
560938
$
```
あれ？元に戻りました。ディスアセンブルしてみると…
```
$ objdump -S hoge | less
...
    static void func(hoge* instance) {
    1590:       f3 0f 1e fa             endbr64 
    1594:       ba 10 27 00 00          mov    $0x2710,%edx
    1599:       0f 1f 80 00 00 00 00    nopl   0x0(%rax)
        for(int i = 0; i < 10000; ++i) instance->value++;
    15a0:       8b 07                   mov    (%rdi),%eax
    15a2:       83 c0 01                add    $0x1,%eax
    15a5:       89 07                   mov    %eax,(%rdi)
    15a7:       83 ea 01                sub    $0x1,%edx
    15aa:       75 f4                   jne    15a0 <_ZN4hoge4funcEPS_+0x10>
    }
    15ac:       c3                      ret    
    15ad:       0f 1f 00                nopl   (%rax)
...
```
インクリメントしてる部分はこうなっています。
```console
    15a0:       8b 07                   mov    (%rdi),%eax
    15a2:       83 c0 01                add    $0x1,%eax
    15a5:       89 07                   mov    %eax,(%rdi)
```
惜しい！3命令になってます。が、読み込みと書き込みが別の命令になってるので、確実に競合が発生してしまいます。最適化＋volatileでは力不足なようです。

# mutexで同期する

マルチスレッドで複数のスレッドから同時にアクセスされる変数がある場合は、普通mutexを使って同期します(今回は[std::thread](https://cpprefjp.github.io/reference/thread/thread.html)を使っているので[std::mutex](https://cpprefjp.github.io/reference/mutex/mutex.html))。

```c++
#include <iostream>
#include <thread>
#include <mutex>
#include <vector>

class hoge {
    volatile int value;
    std::vector<std::thread> threads;
    std::mutex mutex;
public:
    hoge(): value(0), threads(0) {}
    void start() {threads.emplace_back(std::thread(func, this));}
    static void func(hoge* instance) {
        for(int i = 0; i < 10000; ++i) {
            std::lock_guard<std::mutex> lock(instance->mutex);
            instance->value++;
        }
    }
    int join() {
        for (auto& t: threads) t.join();
        return value;
    }
};

int main() {
    hoge o;
    for (int i = 0; i < 100; ++i) o.start();
    std::cout << o.join() << std::endl;
    return 0;
}
```
メンバ変数に
```c++
    std::mutex mutex;
```
を追加し、スレッドのワーカー関数に
```c++
            std::lock_guard<std::mutex> lock(instance->mutex);
```
というのを加えただけです。これを実行すると、
```console
$ g++ -g -O3 hoge.cpp -o hoge
$ ./hoge
1000000
$
```
と正しい結果になり、ディスアセンブル結果も、
```console
$ objdump -S hoge | less
...
    static void func(hoge* instance) {
    1620:       f3 0f 1e fa             endbr64 
    1624:       41 54                   push   %r12
    mutex& operator=(const mutex&) = delete;

    void
    lock()
    {
      int __e = __gthread_mutex_lock(&_M_mutex);
    1626:       4c 8d 67 20             lea    0x20(%rdi),%r12
    162a:       55                      push   %rbp
    162b:       48 89 fd                mov    %rdi,%rbp
    162e:       53                      push   %rbx
    162f:       bb 10 27 00 00          mov    $0x2710,%ebx
    1634:       0f 1f 40 00             nopl   0x0(%rax)

static inline int
__gthread_mutex_lock (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    return __gthrw_(pthread_mutex_lock) (__mutex);
    1638:       4c 89 e7                mov    %r12,%rdi
    163b:       e8 30 fc ff ff          call   1270 <pthread_mutex_lock@plt>

      // EINVAL, EAGAIN, EBUSY, EINVAL, EDEADLK(may)
      if (__e)
    1640:       85 c0                   test   %eax,%eax
    1642:       75 1b                   jne    165f <_ZN4hoge4funcEPS_+0x3f>
            instance->value++;
    1644:       8b 45 00                mov    0x0(%rbp),%eax

static inline int
__gthread_mutex_unlock (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    return __gthrw_(pthread_mutex_unlock) (__mutex);
    1647:       4c 89 e7                mov    %r12,%rdi
    164a:       83 c0 01                add    $0x1,%eax
    164d:       89 45 00                mov    %eax,0x0(%rbp)
    1650:       e8 8b fb ff ff          call   11e0 <pthread_mutex_unlock@plt>
        for(int i = 0; i < 10000; ++i) {
    1655:       83 eb 01                sub    $0x1,%ebx
    1658:       75 de                   jne    1638 <_ZN4hoge4funcEPS_+0x18>
    }
    165a:       5b                      pop    %rbx
    165b:       5d                      pop    %rbp
    165c:       41 5c                   pop    %r12
    165e:       c3                      ret    
        __throw_system_error(__e);
    165f:       89 c7                   mov    %eax,%edi
    1661:       e8 5a fb ff ff          call   11c0 <_ZSt20__throw_system_errori@plt>
    1666:       66 2e 0f 1f 84 00 00    cs nopw 0x0(%rax,%rax,1)
    166d:       00 00 00 
...
```
なんか長いですね…ちょっとmutex操作がinlineで入って見にくくなってますが、インクリメントしてるところは以下になります。
```console
static inline int
__gthread_mutex_lock (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    return __gthrw_(pthread_mutex_lock) (__mutex);
    1638:       4c 89 e7                mov    %r12,%rdi
    163b:       e8 30 fc ff ff          call   1270 <pthread_mutex_lock@plt>

      // EINVAL, EAGAIN, EBUSY, EINVAL, EDEADLK(may)
      if (__e)
    1640:       85 c0                   test   %eax,%eax
    1642:       75 1b                   jne    165f <_ZN4hoge4funcEPS_+0x3f>
            instance->value++;
    1644:       8b 45 00                mov    0x0(%rbp),%eax

static inline int
__gthread_mutex_unlock (__gthread_mutex_t *__mutex)
{
  if (__gthread_active_p ())
    return __gthrw_(pthread_mutex_unlock) (__mutex);
    1647:       4c 89 e7                mov    %r12,%rdi
    164a:       83 c0 01                add    $0x1,%eax
    164d:       89 45 00                mov    %eax,0x0(%rbp)
    1650:       e8 8b fb ff ff          call   11e0 <pthread_mutex_unlock@plt>
```
このmutexで守られているcritical sectionは
```console
    1644:       8b 45 00                mov    0x0(%rbp),%eax
...
    1647:       4c 89 e7                mov    %r12,%rdi
    164a:       83 c0 01                add    $0x1,%eax
    164d:       89 45 00                mov    %eax,0x0(%rbp)
```
この部分です(インクリメントをしているのはこの内3命令になります)。この部分は他のスレッドと同時に実行されないため、意図した通りの動きをして、かつ競合が起きず、正しい結果になったというわけです。なお、今回は最適化していますが、最適化していなくてもmutexなら正しく動きます。

同期方法としてはmutexが一番確実です。ただし、慣れないとすぐロックし忘れが起こるので**難しい**という印象をよく持たれます。丁寧に記述し、抜け漏れさえなければいいだけなので実際には簡単です。ただシングルスレッド非同期と比べると、共有される変数を特別視する必要がある分、比較的難しいとは言えます。

# std::atomicを使う

std::mutexを使うと確実で安全なマルチスレッドプログラムが書けますが、たかがインクリメントをしたいだけなのに大仰すぎるという感じもします。次はデータ競合を防ぐより挑戦的な方法として、[std::atomic](https://cpprefjp.github.io/reference/atomic/atomic.html)があるので、それを使ってみます。

```c++
#include <iostream>
#include <thread>
#include <atomic>
#include <vector>

class hoge {
    std::atomic<int> value;
    std::vector<std::thread> threads;
public:
    hoge(): value(0), threads(0) {}
    void start() {threads.emplace_back(std::thread(func, this));}
    static void func(hoge* instance) {
        for(int i = 0; i < 10000; ++i) {instance->value++;}
    }
    int join() {
        for (auto& t: threads) t.join();
        return value;
    }
};

int main() {
    hoge o;
    for (int i = 0; i < 100; ++i) o.start();
    std::cout << o.join() << std::endl;
    return 0;
}
```
これを実行すると…
```console
$ g++ -g -O3 hoge.cpp -o hoge
$ ./hoge
1000000
$
```
ディスアセンブルは…
```console
    static void func(hoge* instance) {
    15b0:       f3 0f 1e fa             endbr64 
#endif // __cpp_lib_atomic_wait

      _GLIBCXX_ALWAYS_INLINE __int_type
      fetch_add(__int_type __i,
                memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_add(&_M_i, __i, int(__m)); }
    15b4:       b8 10 27 00 00          mov    $0x2710,%eax
    15b9:       0f 1f 80 00 00 00 00    nopl   0x0(%rax)
    15c0:       f0 83 07 01             lock addl $0x1,(%rdi)
        for(int i = 0; i < 10000; ++i) {instance->value++;}
    15c4:       83 e8 01                sub    $0x1,%eax
    15c7:       75 f7                   jne    15c0 <_ZN4hoge4funcEPS_+0x10>
    }
    15c9:       c3                      ret    
    15ca:       66 0f 1f 44 00 00       nopw   0x0(%rax,%rax,1)
```
インクリメントしてるのは…
```console
15c0:       f0 83 07 01             lock addl $0x1,(%rdi)
```
と理想的な形になりました。命令レベルでlock指定があるので、アウト・オブ・オーダー実行やCPUキャッシュの影響なども受けません。ただし、std::atomicは正しいのかどうかの判断も困難なので、理解して使わないと間違った結果を招きやすいようです。かくいう私自身もちゃんと理解できてない部分があります。

# まとめ

- マルチスレッドは同期をしてあげないと競合が発生して正しく動作しない
- 競合の対処には基本mutexを使用する
- データ競合の場合はstd::atomicでも対応できる

# おまけ

私の環境だと上のプログラムではstd::mutexよりstd::atomicの方が5～6倍程度速いです。

# おまけ2: シグナルとスレッドの関係について

マルチスレッドでは競合が起こるので、複数スレッドからアクセスされる変数には同期が必要だという話をしました。では例えばmutexのロックを取っている間、シグナルハンドラは呼ばれるのでしょうか？
答えはyesです。そこには関係がありません。シグナルは割り込みなので、典型的には決められた/指定されたスレッドのスタックにレジスタセットを保存していきなりジャンプします。割り込みから戻るとレジスタを復元して何食わぬ顔をして続きを実行するという仕組みです。

なのでシングルスレッドでも任意のタイミングで処理が突然割り込むわけです。従って、スレッドセーフだからシグナルセーフかというとそうでもない、という感じになります。以前書きましたが、シグナルに出来るのはマスクすることだけで、スレッドに対するmutexのような同期の仕組みもありません。

# おまけ3: 非同期処理とスレッドの関係について

.NETなどを書いていると分かりますが、非同期処理で記述していると(Task生成時に)勝手に新しいスレッドが割り当てられていたりすることがあります。マルチスレッドかつ非同期という組み合わせが容易に発生するということで、逆に非同期と言ってるからといって、必ずしもシングルスレッドかというわけでもないということです。非同期処理で記述していても、複数スレッドから同時に読み書きされるものにはMutexなどによる同期が必要になります。

